{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/vol/biomedic3/mb121/calibration_exploration/\")\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from default_paths import ROOT\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_foundation_models = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = [\n",
    "    \"base_density\",\n",
    "    \"base_camelyon\",\n",
    "    \"base_retina\",\n",
    "    \"base_living17\",\n",
    "    \"base_entity30\",\n",
    "    \"base_domainnet\",\n",
    "    \"base_icam\",\n",
    "    \"base_chexpert\",\n",
    "]\n",
    "\n",
    "\n",
    "cm = sns.color_palette(\"Paired\")\n",
    "palette = {\n",
    "    \"PROBAS\": \"black\",\n",
    "    \"TS\": cm[0],\n",
    "    \"IRM\": cm[2],\n",
    "    \"ETS\": cm[4],\n",
    "    \"IROVATS\": cm[6],\n",
    "    \"EBS_MINUS\": cm[8],\n",
    "    \"EBS\": cm[9],\n",
    "    \"TS_WITH_OOD\": cm[1],\n",
    "    \"IRM_WITH_OOD\": cm[3],\n",
    "    \"IROVATS_WITH_OOD\": cm[7],\n",
    "    \"PSEUDO_LOGITS_PROBAS_ENS_TS\": cm[0],\n",
    "    \"PSEUDO_LOGITS_PROBAS_ENS_EBS\": cm[9],\n",
    "    \"PSEUDO_LOGITS_PROBAS_ENS_TS_OOD\": cm[1],\n",
    "}\n",
    "\n",
    "\n",
    "def fn(x, pos):\n",
    "    return f\"{x:.3f}\".lstrip(\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main paper figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"ECE\", \"Brier\"]\n",
    "c2 = [\n",
    "    \"probas\",\n",
    "    \"calib_ebs\",\n",
    "    \"calib_ts\",\n",
    "    \"calib_irm\",\n",
    "    \"calib_irovats\",\n",
    "    \"calib_irm_with_ood\",\n",
    "    \"calib_ts_with_ood\",\n",
    "    \"calib_irovats_with_ood\",\n",
    "    \"pseudo_logits_probas_ens\",\n",
    "    \"pseudo_logits_probas_ens_ts\",\n",
    "    \"pseudo_logits_probas_ens_ebs\",\n",
    "    \"pseudo_logits_probas_ens_ts_ood\",\n",
    "]\n",
    "for experiment in all_experiments:\n",
    "    all_dfs = defaultdict(list)\n",
    "    all_baseline_dfs = defaultdict(list)\n",
    "    for k in metrics_list:\n",
    "        for ls, er in [(0, 0), (0.05, 0.1)]:\n",
    "            ensemble_output_dir = ROOT / Path(\n",
    "                f\"outputs/ensembling_results/{experiment}/{float(ls):.2f}_{float(er):.2f}_{evaluate_foundation_models}\"\n",
    "            )\n",
    "            df = pd.read_csv(\n",
    "                ensemble_output_dir / f\"all_ensemble_metrics_{k}.csv\", index_col=0\n",
    "            )\n",
    "            clean_name = {c: c.replace(\"calib_\", \"\").upper() for c in c2}\n",
    "            df.rename(columns=clean_name, inplace=True)\n",
    "            df[\"domain\"] = df.index.values\n",
    "            df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "            df[\"experiment\"] = experiment\n",
    "            df[\"foundation\"] = evaluate_foundation_models\n",
    "            df[\"metric\"] = k\n",
    "            df[\"loss\"] = \"CE\" if (ls == er == 0) else \"ER+LS\"\n",
    "            all_dfs[k].append(df)\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                ensemble_output_dir / f\"individual_run_metrics_{k}.csv\", index_col=0\n",
    "            )\n",
    "            clean_name = {c: c.replace(\"calib_\", \"\").upper() for c in c2}\n",
    "            df.rename(columns=clean_name, inplace=True)\n",
    "            df[\"domain\"] = df.index.values\n",
    "            df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "            df[\"experiment\"] = experiment\n",
    "            df[\"metric\"] = k\n",
    "            df[\"loss\"] = \"CE\" if (ls == er == 0) else \"ER+LS\"\n",
    "            df[\"foundation\"] = evaluate_foundation_models\n",
    "            all_baseline_dfs[k].append(df)\n",
    "\n",
    "    for j, m in enumerate([\"ECE\", \"Brier\"]):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(2.3, 2.9))\n",
    "        df1 = pd.concat(all_dfs[m])\n",
    "        df2 = df1.drop(columns=[\"metric\", \"foundation\"])\n",
    "        df3 = df2.melt(\n",
    "            value_vars=[\n",
    "                \"EBS\",\n",
    "                \"TS\",\n",
    "                \"PROBAS\",\n",
    "                \"IRM\",\n",
    "                \"TS_WITH_OOD\",\n",
    "                \"IRM_WITH_OOD\",\n",
    "                \"IROVATS\",\n",
    "                \"IROVATS_WITH_OOD\",\n",
    "                \"pseudo_logits_probas_ens_ts\".upper(),\n",
    "                \"pseudo_logits_probas_ens_ebs\".upper(),\n",
    "                \"pseudo_logits_probas_ens_ts_ood\".upper(),\n",
    "            ],\n",
    "            id_vars=[\"experiment\", \"loss\", \"domain\"],\n",
    "        )\n",
    "        df3[\"treatment\"] = df3[\"loss\"] + \" + \" + df3[\"variable\"]\n",
    "        df_calib_after = df3.loc[\n",
    "            df3[\"treatment\"].isin(\n",
    "                [\n",
    "                    \"CE + \" + \"pseudo_logits_probas_ens_ebs\".upper(),\n",
    "                    \"CE + \" + \"pseudo_logits_probas_ens_ts\".upper(),\n",
    "                    \"CE + \" + \"pseudo_logits_probas_ens_ts_ood\".upper(),\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        c3 = [\n",
    "            \"CE + EBS\",\n",
    "            \"CE + TS\",\n",
    "            \"CE + PROBAS\",\n",
    "            \"CE + TS_WITH_OOD\",\n",
    "            \"ER+LS + PROBAS\",\n",
    "        ]\n",
    "        df3 = df3.loc[df3[\"treatment\"].isin(c3)]\n",
    "\n",
    "        df_calib_after = (\n",
    "            pd.merge(\n",
    "                df_calib_after.loc[df_calib_after.domain == \"ID\"].drop(\n",
    "                    columns=\"domain\"\n",
    "                ),\n",
    "                df_calib_after.loc[df_calib_after.domain == \"OOD\"].drop(\n",
    "                    columns=\"domain\"\n",
    "                ),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean()\n",
    "        )\n",
    "        df5 = (\n",
    "            pd.merge(\n",
    "                df3.loc[df3.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "                df3.loc[df3.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        df1_base = pd.concat(all_baseline_dfs[m])\n",
    "        df1_base = df1_base.drop(columns=[\"metric\", \"foundation\"])\n",
    "        df1_base = df1_base.melt(\n",
    "            value_vars=[\n",
    "                \"EBS\",\n",
    "                \"TS\",\n",
    "                \"PROBAS\",\n",
    "                \"IRM\",\n",
    "                \"TS_WITH_OOD\",\n",
    "                \"IRM_WITH_OOD\",\n",
    "                \"IROVATS\",\n",
    "                \"IROVATS_WITH_OOD\",\n",
    "            ],\n",
    "            id_vars=[\"experiment\", \"loss\", \"domain\"],\n",
    "        )\n",
    "        df1_base[\"treatment\"] = df1_base[\"loss\"] + \" + \" + df1_base[\"variable\"]\n",
    "        df1_base = df1_base.loc[df1_base[\"treatment\"].isin(c3)]\n",
    "        df1_base = (\n",
    "            pd.merge(\n",
    "                df1_base.loc[df1_base.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "                df1_base.loc[df1_base.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean()\n",
    "        )\n",
    "        sns.scatterplot(\n",
    "            data=df1_base,\n",
    "            style=\"loss\",\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=30,\n",
    "            ax=ax,\n",
    "            markers={\"CE\": \"o\", \"ER\": \"P\", \"LS\": \"X\", \"Focal\": \"v\", \"ER+LS\": \"D\"},\n",
    "            palette=palette,\n",
    "            legend=False,\n",
    "        )\n",
    "\n",
    "        df5 = df5.reset_index()\n",
    "        for xp, yp, var in zip(\n",
    "            np.stack([df5.value_id.values, df1_base.value_id.values], 1),\n",
    "            np.stack([df5.value_ood.values, df1_base.value_ood.values], 1),\n",
    "            df5.variable.values,\n",
    "        ):\n",
    "            ax.plot(xp, yp, c=palette[var], ls=\":\", linewidth=1)\n",
    "\n",
    "        df1_base = df1_base.reset_index()\n",
    "        df1_base = df1_base.loc[\n",
    "            df1_base[\"treatment\"].isin([\"CE + EBS\", \"CE + TS\", \"CE + TS_WITH_OOD\"])\n",
    "        ]\n",
    "        df_calib_after = df_calib_after.reset_index()\n",
    "\n",
    "        for xp, yp, var in zip(\n",
    "            np.stack([df_calib_after.value_id.values, df1_base.value_id.values], 1),\n",
    "            np.stack([df_calib_after.value_ood.values, df1_base.value_ood.values], 1),\n",
    "            df1_base[\"variable\"].values,\n",
    "        ):\n",
    "            ax.plot(xp, yp, c=palette[var], ls=\":\", linewidth=1)\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=df5,\n",
    "            style=\"loss\",\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=100,\n",
    "            legend=True,\n",
    "            ax=ax,\n",
    "            markers={\"CE\": \"o\", \"ER\": \"P\", \"LS\": \"X\", \"Focal\": \"v\", \"ER+LS\": \"D\"},\n",
    "            palette=palette,\n",
    "            edgecolor=\"dimgrey\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=df_calib_after,\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=100,\n",
    "            legend=True,\n",
    "            ax=ax,  # style='loss',\n",
    "            markers={\"CE\": \"o\", \"ER+LS\": \"P\"},\n",
    "            palette=palette,\n",
    "            marker=\"$\\circ$\",\n",
    "            ec=\"face\",\n",
    "            linewidth=1.5,  # \"$\\diamond$\"\n",
    "        )\n",
    "\n",
    "        # Get handles and labels directly from the axes\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        # Remove the legend from its current position\n",
    "        if m == \"ECE\" and experiment == \"base_icam\":\n",
    "            ax.set_xlim((0, 0.25))\n",
    "            ax.set_ylim((0, 0.30))\n",
    "        ax.get_legend().remove()\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "        (\n",
    "            ax.set_ylabel(\"$\\mathbf{\" + m.upper() + \"}$\" + \" - SHIFTED\")\n",
    "            if experiment == \"base_living17\"\n",
    "            else ax.set_ylabel(\"\")\n",
    "        )\n",
    "        ax.set_xlabel(\"ID\")\n",
    "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(fn))\n",
    "        ax.yaxis.set_major_formatter(ticker.FuncFormatter(fn))\n",
    "        if m == \"ECE\":\n",
    "            match experiment:\n",
    "                case \"base_chexpert\":\n",
    "                    f.suptitle(\"$\\mathbf{CXR}$\")\n",
    "                case \"base_density\":\n",
    "                    f.suptitle(\"$\\mathbf{EMBED}$\")\n",
    "                case _:\n",
    "                    f.suptitle(\n",
    "                        \"$\\mathbf{\" + experiment.replace(\"base_\", \"\").upper() + \"}$\"\n",
    "                    )\n",
    "        f.savefig(\n",
    "            f\"/vol/biomedic3/mb121/calibration_exploration/outputs/figures/ensemble/main/{m}/{experiment}_{evaluate_foundation_models}.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: pre/post calibration with ERLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in all_experiments:\n",
    "    all_dfs = defaultdict(list)\n",
    "    all_baseline_dfs = defaultdict(list)\n",
    "    for k in metrics_list:\n",
    "        for ls, er in [(0, 0), (0.05, 0.1)]:\n",
    "            for evaluate_foundation_models in [False]:\n",
    "                ensemble_output_dir = ROOT / Path(\n",
    "                    f\"outputs/ensembling_results/{experiment}/{float(ls):.2f}_{float(er):.2f}_{evaluate_foundation_models}\"\n",
    "                )\n",
    "                df = pd.read_csv(\n",
    "                    ensemble_output_dir / f\"all_ensemble_metrics_{k}.csv\", index_col=0\n",
    "                )\n",
    "                clean_name = {c: c.replace(\"calib_\", \"\").upper() for c in c2}\n",
    "                df.rename(columns=clean_name, inplace=True)\n",
    "                df[\"domain\"] = df.index.values\n",
    "                df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "                df[\"experiment\"] = experiment\n",
    "                df[\"foundation\"] = evaluate_foundation_models\n",
    "                df[\"metric\"] = k\n",
    "                df[\"loss\"] = \"CE\" if (ls == er == 0) else \"ER+LS\"\n",
    "                all_dfs[k].append(df)\n",
    "\n",
    "                df = pd.read_csv(\n",
    "                    ensemble_output_dir / f\"individual_run_metrics_{k}.csv\", index_col=0\n",
    "                )\n",
    "                clean_name = {c: c.replace(\"calib_\", \"\").upper() for c in c2}\n",
    "                df.rename(columns=clean_name, inplace=True)\n",
    "                df[\"domain\"] = df.index.values\n",
    "                df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "                df[\"experiment\"] = experiment\n",
    "                df[\"metric\"] = k\n",
    "                df[\"loss\"] = \"CE\" if (ls == er == 0) else \"ER+LS\"\n",
    "                df[\"foundation\"] = evaluate_foundation_models\n",
    "                all_baseline_dfs[k].append(df)\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    f, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    for j, m in enumerate([\"ECE\", \"Brier\"]):\n",
    "        df1 = pd.concat(all_dfs[m])\n",
    "        df2 = df1.drop(\n",
    "            columns=[\"metric\", \"foundation\"]\n",
    "        )  # .groupby(['experiment', 'loss', 'domain'], as_index=False).mean()\n",
    "        df3 = df2.melt(\n",
    "            value_vars=[\n",
    "                \"EBS\",\n",
    "                \"TS\",\n",
    "                \"PROBAS\",\n",
    "                \"IRM\",\n",
    "                \"TS_WITH_OOD\",\n",
    "                \"IRM_WITH_OOD\",\n",
    "                \"IROVATS\",\n",
    "                \"IROVATS_WITH_OOD\",\n",
    "                \"pseudo_logits_probas_ens_ts\".upper(),\n",
    "                \"pseudo_logits_probas_ens_ebs\".upper(),\n",
    "                \"pseudo_logits_probas_ens_ts_ood\".upper(),\n",
    "            ],\n",
    "            id_vars=[\"experiment\", \"loss\", \"domain\"],\n",
    "        )\n",
    "        df3[\"treatment\"] = df3[\"loss\"] + \" + \" + df3[\"variable\"]\n",
    "        df_calib_after = df3.loc[\n",
    "            df3[\"treatment\"].isin(\n",
    "                [\n",
    "                    \"ER+LS + \" + \"pseudo_logits_probas_ens_ebs\".upper(),\n",
    "                    \"ER+LS + \" + \"pseudo_logits_probas_ens_ts\".upper(),\n",
    "                    \"ER+LS + \" + \"pseudo_logits_probas_ens_ts_ood\".upper(),\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        c3 = [\n",
    "            \"ER+LS + EBS\",\n",
    "            \"ER+LS + TS\",\n",
    "            \"ER+LS + TS_WITH_OOD\",\n",
    "            \"ER+LS + PROBAS\",\n",
    "        ]  # 'CE + IROVATS', 'CE + IROVATS_WITH_OOD', 'CE + IRM_WITH_OOD', 'CE + IRM',\n",
    "        df_base_ce = df3.loc[df3[\"treatment\"] == \"CE + TS\"]\n",
    "        df3 = df3.loc[df3[\"treatment\"].isin(c3)]\n",
    "\n",
    "        df_calib_after = (\n",
    "            pd.merge(\n",
    "                df_calib_after.loc[df_calib_after.domain == \"ID\"].drop(\n",
    "                    columns=\"domain\"\n",
    "                ),\n",
    "                df_calib_after.loc[df_calib_after.domain == \"OOD\"].drop(\n",
    "                    columns=\"domain\"\n",
    "                ),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean()\n",
    "        )\n",
    "        df5 = (\n",
    "            pd.merge(\n",
    "                df3.loc[df3.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "                df3.loc[df3.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean()\n",
    "        )\n",
    "        sns.scatterplot(\n",
    "            data=df5,\n",
    "            style=\"loss\",\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=140,\n",
    "            legend=j == 0,\n",
    "            ax=ax[j],\n",
    "            markers={\"CE\": \"o\", \"ER\": \"P\", \"LS\": \"X\", \"Focal\": \"v\", \"ER+LS\": \"D\"},\n",
    "            palette=palette,\n",
    "            edgecolor=\"dimgrey\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=df_calib_after,\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=275,\n",
    "            legend=j == 0,\n",
    "            ax=ax[j],  # style='loss',\n",
    "            marker=\"$\\diamond$\",\n",
    "            ec=\"face\",\n",
    "            palette=palette,  # edgecolor='dimgrey', linewidth=0.5\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=pd.merge(\n",
    "                df_base_ce.loc[df_base_ce.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "                df_base_ce.loc[df_base_ce.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean(),\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=140,\n",
    "            legend=j == 0,\n",
    "            ax=ax[j],\n",
    "            style=\"loss\",\n",
    "            markers={\"CE\": \"o\"},\n",
    "            palette=palette,\n",
    "            edgecolor=\"red\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "        df1_base = pd.concat(all_baseline_dfs[m])\n",
    "        df1_base = df1_base.drop(\n",
    "            columns=[\"metric\", \"foundation\"]\n",
    "        )  # .groupby(['experiment', 'loss', 'domain'], as_index=False).mean()\n",
    "        df1_base = df1_base.melt(\n",
    "            value_vars=[\n",
    "                \"EBS\",\n",
    "                \"TS\",\n",
    "                \"PROBAS\",\n",
    "                \"IRM\",\n",
    "                \"TS_WITH_OOD\",\n",
    "                \"IRM_WITH_OOD\",\n",
    "                \"IROVATS\",\n",
    "                \"IROVATS_WITH_OOD\",\n",
    "            ],\n",
    "            id_vars=[\"experiment\", \"loss\", \"domain\"],\n",
    "        )\n",
    "        df1_base[\"treatment\"] = df1_base[\"loss\"] + \" + \" + df1_base[\"variable\"]\n",
    "        df1_base = df1_base.loc[df1_base[\"treatment\"].isin(c3)]\n",
    "        df1_base = (\n",
    "            pd.merge(\n",
    "                df1_base.loc[df1_base.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "                df1_base.loc[df1_base.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "                on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "                suffixes=[\"_id\", \"_ood\"],\n",
    "            )\n",
    "            .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "            .mean()\n",
    "        )\n",
    "        sns.scatterplot(\n",
    "            data=df1_base,\n",
    "            style=\"loss\",\n",
    "            hue=\"variable\",\n",
    "            y=\"value_ood\",\n",
    "            x=\"value_id\",\n",
    "            s=40,\n",
    "            ax=ax[j],\n",
    "            markers={\"CE\": \"o\", \"ER\": \"P\", \"LS\": \"X\", \"Focal\": \"v\", \"ER+LS\": \"D\"},\n",
    "            palette=palette,\n",
    "            legend=False,\n",
    "        )\n",
    "\n",
    "        df5 = df5.reset_index()\n",
    "        df5 = df5.loc[df5[\"treatment\"].isin(c3)]\n",
    "        for xp, yp, var in zip(\n",
    "            np.stack([df5.value_id.values, df1_base.value_id.values], 1),\n",
    "            np.stack([df5.value_ood.values, df1_base.value_ood.values], 1),\n",
    "            df5.variable.values,\n",
    "        ):\n",
    "            ax[j].plot(xp, yp, c=palette[var], ls=\":\")\n",
    "        df1_base = df1_base.reset_index()\n",
    "        df1_base = df1_base.loc[\n",
    "            df1_base[\"treatment\"].isin(\n",
    "                [\"ER+LS + EBS\", \"ER+LS + TS\", \"ER+LS + TS_WITH_OOD\"]\n",
    "            )\n",
    "        ]\n",
    "        for xp, yp, var in zip(\n",
    "            np.stack([df_calib_after.value_id.values, df1_base.value_id.values], 1),\n",
    "            np.stack([df_calib_after.value_ood.values, df1_base.value_ood.values], 1),\n",
    "            df1_base[\"variable\"].values,\n",
    "        ):\n",
    "            ax[j].plot(xp, yp, c=palette[var], ls=\":\")\n",
    "\n",
    "        if 0 == j:\n",
    "            # Get handles and labels directly from the axes\n",
    "            handles, labels = ax[0].get_legend_handles_labels()\n",
    "            # Remove the legend from its current position\n",
    "            ax[0].get_legend().remove()\n",
    "        ax[j].set_xlabel(\"\")\n",
    "\n",
    "    ax[0].set_ylabel(\"SHIFTED\")\n",
    "    ax[0].set_xlabel(\"ID\")\n",
    "    ax[1].set_ylabel(\"SHIFTED\")\n",
    "    ax[1].set_xlabel(\"ID\")\n",
    "    ax[0].set_title(\"ECE\")\n",
    "    ax[1].set_title(\"Brier\")\n",
    "    ax[1].set_ylabel(\"\")\n",
    "    f2, ax2 = plt.subplots(1, 1, figsize=(10, 1))\n",
    "    ax2.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc=\"center\",  # Center the legend\n",
    "        ncol=12,  # Display legend items in 3 columns\n",
    "    )\n",
    "    ax2.axis(\"off\")\n",
    "    f2.tight_layout()\n",
    "    f2.savefig(\n",
    "        f\"/vol/biomedic3/mb121/calibration_exploration/outputs/figures/ensemble/erls/legend.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    match experiment:\n",
    "        case \"base_chexpert\":\n",
    "            f.suptitle(\"$\\mathbf{CXR}$\")\n",
    "        case \"base_density\":\n",
    "            f.suptitle(\"$\\mathbf{EMBED}$\")\n",
    "        case _:\n",
    "            f.suptitle(\"$\\mathbf{\" + experiment.replace(\"base_\", \"\").upper() + \"}$\")\n",
    "    f.savefig(\n",
    "        f\"/vol/biomedic3/mb121/calibration_exploration/outputs/figures/ensemble/erls/{experiment}.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: full comparison of post-hoc calibrator (pre + CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = defaultdict(list)\n",
    "all_baseline_dfs = defaultdict(list)\n",
    "for k in metrics_list:\n",
    "    for ls, er in [(0, 0), (0.05, 0.1)]:\n",
    "        for evaluate_foundation_models in [False]:\n",
    "            ensemble_output_dir = ROOT / Path(\n",
    "                f\"outputs/ensembling_results/{experiment}/{float(ls):.2f}_{float(er):.2f}_{evaluate_foundation_models}\"\n",
    "            )\n",
    "            df = pd.read_csv(\n",
    "                ensemble_output_dir / f\"all_ensemble_metrics_{k}.csv\", index_col=0\n",
    "            )\n",
    "            clean_name = {c: c.replace(\"calib_\", \"\").upper() for c in c2}\n",
    "            df.rename(columns=clean_name, inplace=True)\n",
    "            df[\"domain\"] = df.index.values\n",
    "            df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "            df[\"experiment\"] = experiment\n",
    "            df[\"foundation\"] = evaluate_foundation_models\n",
    "            df[\"metric\"] = k\n",
    "            df[\"loss\"] = \"CE\" if (ls == er == 0) else \"ER+LS\"\n",
    "            all_dfs[k].append(df)\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                ensemble_output_dir / f\"individual_run_metrics_{k}.csv\", index_col=0\n",
    "            )\n",
    "            clean_name = {c: c.replace(\"calib_\", \"\").upper() for c in c2}\n",
    "            df.rename(columns=clean_name, inplace=True)\n",
    "            df[\"domain\"] = df.index.values\n",
    "            df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "            df[\"experiment\"] = experiment\n",
    "            df[\"metric\"] = k\n",
    "            df[\"loss\"] = \"CE\" if (ls == er == 0) else \"ER+LS\"\n",
    "            df[\"foundation\"] = evaluate_foundation_models\n",
    "            all_baseline_dfs[k].append(df)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "colors_blue = sns.color_palette(\"Blues_r\", n_colors=5)\n",
    "my_palette = {\n",
    "    \"CE + PROBAS\": colors_blue[0],\n",
    "    \"CE + TS\": colors_blue[1],\n",
    "    \"CE + IRM\": colors_blue[2],\n",
    "    \"CE + EBS\": colors_blue[3],\n",
    "    \"CE + EBS_DAC\": colors_blue[4],\n",
    "    \"ER+LS + PROBAS\": \"darkred\",\n",
    "    \"ER+LS + EBS\": \"indianred\",\n",
    "}\n",
    "\n",
    "\n",
    "for j, m in enumerate([\"ECE\", \"Brier\"]):\n",
    "    df1 = pd.concat(all_dfs[m])\n",
    "    df2 = df1.drop(columns=[\"metric\", \"foundation\"])\n",
    "    df3 = df2.melt(\n",
    "        value_vars=[\n",
    "            \"EBS\",\n",
    "            \"TS\",\n",
    "            \"PROBAS\",\n",
    "            \"IRM\",\n",
    "            \"TS_WITH_OOD\",\n",
    "            \"IRM_WITH_OOD\",\n",
    "            \"IROVATS\",\n",
    "            \"IROVATS_WITH_OOD\",\n",
    "        ],\n",
    "        id_vars=[\"experiment\", \"loss\", \"domain\"],\n",
    "    )\n",
    "    df3[\"treatment\"] = df3[\"loss\"] + \" + \" + df3[\"variable\"]\n",
    "\n",
    "    c3 = [\n",
    "        \"CE + EBS\",\n",
    "        \"CE + TS\",\n",
    "        \"CE + PROBAS\",\n",
    "        \"CE + TS_WITH_OOD\",\n",
    "        \"CE + IROVATS\",\n",
    "        \"CE + IROVATS_WITH_OOD\",\n",
    "        \"CE + IRM_WITH_OOD\",\n",
    "        \"CE + IRM\",\n",
    "    ]  #\n",
    "    df3 = df3.loc[df3[\"treatment\"].isin(c3)]\n",
    "\n",
    "    df5 = (\n",
    "        pd.merge(\n",
    "            df3.loc[df3.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "            df3.loc[df3.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "            on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "            suffixes=[\"_id\", \"_ood\"],\n",
    "        )\n",
    "        .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "        .mean()\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=df5,\n",
    "        style=\"loss\",\n",
    "        hue=\"variable\",\n",
    "        y=\"value_ood\",\n",
    "        x=\"value_id\",\n",
    "        s=140,\n",
    "        legend=j == 0,\n",
    "        ax=ax[j],\n",
    "        markers={\"CE\": \"o\", \"ER\": \"P\", \"LS\": \"X\", \"Focal\": \"v\", \"ER+LS\": \"D\"},\n",
    "        palette=palette,\n",
    "        edgecolor=\"dimgrey\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    df1_base = pd.concat(all_baseline_dfs[m])\n",
    "    df1_base = df1_base.drop(columns=[\"metric\", \"foundation\"])\n",
    "    df1_base = df1_base.melt(\n",
    "        value_vars=[\n",
    "            \"EBS\",\n",
    "            \"TS\",\n",
    "            \"PROBAS\",\n",
    "            \"IRM\",\n",
    "            \"TS_WITH_OOD\",\n",
    "            \"IRM_WITH_OOD\",\n",
    "            \"IROVATS\",\n",
    "            \"IROVATS_WITH_OOD\",\n",
    "        ],\n",
    "        id_vars=[\"experiment\", \"loss\", \"domain\"],\n",
    "    )\n",
    "    df1_base[\"treatment\"] = df1_base[\"loss\"] + \" + \" + df1_base[\"variable\"]\n",
    "    df1_base = df1_base.loc[df1_base[\"treatment\"].isin(c3)]\n",
    "    df1_base = (\n",
    "        pd.merge(\n",
    "            df1_base.loc[df1_base.domain == \"ID\"].drop(columns=\"domain\"),\n",
    "            df1_base.loc[df1_base.domain == \"OOD\"].drop(columns=\"domain\"),\n",
    "            on=[\"loss\", \"variable\", \"treatment\", \"experiment\"],\n",
    "            suffixes=[\"_id\", \"_ood\"],\n",
    "        )\n",
    "        .groupby([\"loss\", \"variable\", \"treatment\", \"experiment\"])\n",
    "        .mean()\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        data=df1_base,\n",
    "        style=\"loss\",\n",
    "        hue=\"variable\",\n",
    "        y=\"value_ood\",\n",
    "        x=\"value_id\",\n",
    "        s=40,\n",
    "        ax=ax[j],\n",
    "        markers={\"CE\": \"o\", \"ER\": \"P\", \"LS\": \"X\", \"Focal\": \"v\", \"ER+LS\": \"D\"},\n",
    "        palette=palette,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    df5 = df5.reset_index()\n",
    "    df5 = df5.loc[df5[\"treatment\"].isin(c3)]\n",
    "    for xp, yp, var in zip(\n",
    "        np.stack([df5.value_id.values, df1_base.value_id.values], 1),\n",
    "        np.stack([df5.value_ood.values, df1_base.value_ood.values], 1),\n",
    "        df5.variable.values,\n",
    "    ):\n",
    "        ax[j].plot(xp, yp, c=palette[var], ls=\":\")\n",
    "    if 0 == j:\n",
    "        # Get handles and labels directly from the axes\n",
    "        handles, labels = ax[0].get_legend_handles_labels()\n",
    "        # Remove the legend from its current position\n",
    "        ax[0].get_legend().remove()\n",
    "    ax[j].set_xlabel(\"\")\n",
    "\n",
    "ax[0].set_ylabel(\"SHIFTED\")\n",
    "ax[0].set_xlabel(\"ID\")\n",
    "ax[1].set_ylabel(\"SHIFTED\")\n",
    "ax[1].set_xlabel(\"ID\")\n",
    "ax[0].set_title(\"ECE\")\n",
    "ax[1].set_title(\"Brier\")\n",
    "ax[1].set_ylabel(\"\")\n",
    "f2, ax2 = plt.subplots(1, 1, figsize=(10, 1))\n",
    "ax2.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"center\",  # Center the legend\n",
    "    ncol=12,  # Display legend items in 3 columns\n",
    ")\n",
    "ax2.axis(\"off\")\n",
    "f2.tight_layout()\n",
    "f2.savefig(\n",
    "    f\"/vol/biomedic3/mb121/calibration_exploration/outputs/figures/ensemble/posthoc/legend.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "match experiment:\n",
    "    case \"base_chexpert\":\n",
    "        f.suptitle(\"$\\mathbf{CXR}$\")\n",
    "    case \"base_density\":\n",
    "        f.suptitle(\"$\\mathbf{EMBED}$\")\n",
    "    case _:\n",
    "        f.suptitle(\"$\\mathbf{\" + experiment.replace(\"base_\", \"\").upper() + \"}$\")\n",
    "f.savefig(\n",
    "    f\"/vol/biomedic3/mb121/calibration_exploration/outputs/figures/ensemble/posthoc/{experiment}.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
