{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and plot significance study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/vol/biomedic3/mb121/calibration_exploration/\")\n",
    "\n",
    "from classification.load_model_and_config import (\n",
    "    get_run_id_from_config,\n",
    "    _clean_config_for_backward_compatibility,\n",
    ")\n",
    "from hydra import initialize, compose\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "from collections import defaultdict\n",
    "import pingouin\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "all_experiments = [\n",
    "    \"base_density\",\n",
    "    \"base_camelyon\",\n",
    "    \"base_retina\",\n",
    "    \"base_living17\",\n",
    "    \"base_entity30\",\n",
    "    \"base_domainnet\",\n",
    "    \"base_icam\",\n",
    "    \"base_chexpert\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = False\n",
    "model_names = [\n",
    "    \"resnet18\",\n",
    "    \"resnet50\",\n",
    "    \"mobilenetv2_100\",\n",
    "    \"convnext_tiny\",\n",
    "    \"vit_base_patch16_224\",\n",
    "    \"efficientnet_b0\",\n",
    "]  #\n",
    "\n",
    "all_run_ids = defaultdict(list)\n",
    "all_run_ids_ls = defaultdict(list)\n",
    "all_run_ids_er = defaultdict(list)\n",
    "all_run_ids_er_ls = defaultdict(list)\n",
    "all_run_focal = defaultdict(list)\n",
    "\n",
    "for experiment in all_experiments:\n",
    "    configs_to_evaluate = [\n",
    "        [\n",
    "            f\"experiment={experiment}\",\n",
    "            f\"model.encoder_name={model}\",\n",
    "            f\"model.pretrained={pretrained}\",\n",
    "        ]\n",
    "        for model in model_names\n",
    "    ]\n",
    "    with initialize(version_base=None, config_path=\"../configs\"):\n",
    "        for config_str in configs_to_evaluate:\n",
    "            config = compose(\n",
    "                config_name=\"config.yaml\",\n",
    "                overrides=config_str + [\"trainer.label_smoothing=0.00\"],\n",
    "            )\n",
    "            delattr(config.trainer, \"lr\")\n",
    "            _clean_config_for_backward_compatibility(config)\n",
    "            run_id = get_run_id_from_config(\n",
    "                config, allow_multiple_runs=False, allow_return_none_if_no_runs=True\n",
    "            )\n",
    "            if run_id is not None:\n",
    "                all_run_ids[experiment[5:]].append(run_id)\n",
    "            config = compose(\n",
    "                config_name=\"config.yaml\",\n",
    "                overrides=config_str + [\"trainer.label_smoothing=0.05\"],\n",
    "            )\n",
    "            delattr(config.trainer, \"lr\")\n",
    "            _clean_config_for_backward_compatibility(config)\n",
    "            run_id_ls = get_run_id_from_config(\n",
    "                config, allow_multiple_runs=False, allow_return_none_if_no_runs=True\n",
    "            )\n",
    "            if run_id_ls is not None:\n",
    "                all_run_ids_ls[experiment[5:]].append(run_id_ls)\n",
    "\n",
    "            config = compose(\n",
    "                config_name=\"config.yaml\",\n",
    "                overrides=config_str + [\"trainer.entropy_regularisation=0.1\"],\n",
    "            )\n",
    "            delattr(config.trainer, \"lr\")\n",
    "            _clean_config_for_backward_compatibility(config)\n",
    "            run_id_er = get_run_id_from_config(\n",
    "                config, allow_multiple_runs=False, allow_return_none_if_no_runs=True\n",
    "            )\n",
    "            if run_id_er is not None:\n",
    "                all_run_ids_er[experiment[5:]].append(run_id_er)\n",
    "\n",
    "            config = compose(\n",
    "                config_name=\"config.yaml\",\n",
    "                overrides=config_str\n",
    "                + [\n",
    "                    \"trainer.entropy_regularisation=0.1\",\n",
    "                    \"trainer.label_smoothing=0.05\",\n",
    "                ],\n",
    "            )\n",
    "            delattr(config.trainer, \"lr\")\n",
    "            _clean_config_for_backward_compatibility(config)\n",
    "            run_id_er_ls = get_run_id_from_config(\n",
    "                config, allow_multiple_runs=False, allow_return_none_if_no_runs=True\n",
    "            )\n",
    "            if run_id_er_ls is not None:\n",
    "                all_run_ids_er_ls[experiment[5:]].append(run_id_er_ls)\n",
    "\n",
    "            config = compose(\n",
    "                config_name=\"config.yaml\",\n",
    "                overrides=config_str\n",
    "                + [\"trainer.use_focal_loss=True\", \"trainer.focal_loss_gamma=-53\"],\n",
    "            )\n",
    "            delattr(config.trainer, \"lr\")\n",
    "            _clean_config_for_backward_compatibility(config)\n",
    "            run_id = get_run_id_from_config(\n",
    "                config, allow_multiple_runs=False, allow_return_none_if_no_runs=True\n",
    "            )\n",
    "            if run_id is not None:\n",
    "                all_run_focal[experiment[5:]].append(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_metrics_df(list_run_ids, metric, experiment):\n",
    "    all_df = []\n",
    "    for run_id in list_run_ids:\n",
    "        output_dir = Path(\n",
    "            f\"/vol/biomedic3/mb121/calibration_exploration/outputs/run_{run_id}\"\n",
    "        )\n",
    "        try:\n",
    "            df = pd.read_csv(output_dir / f\"metrics_{metric}.csv\")\n",
    "        except FileNotFoundError:\n",
    "            print(str(output_dir / f\"metrics_{metric}.csv\") + \" Not found\")\n",
    "            continue\n",
    "        df.rename(columns={\"Unnamed: 0\": \"domain\"}, inplace=True)\n",
    "        if \"brightness_s0\" in df.domain.values:\n",
    "            df[\"domain\"] = df[\"domain\"].apply(\n",
    "                lambda x: (int(x[-1]) + 1) if x != \"id\" else \"id\"\n",
    "            )\n",
    "        df[\"domain\"] = df[\"domain\"].map(lambda x: \"ID\" if \"id\" == x else \"OOD\")\n",
    "        df = df.groupby(\"domain\").mean()\n",
    "        # df['domain'] = df.index\n",
    "        df[\"dataset\"] = experiment\n",
    "        df.reset_index(inplace=True)\n",
    "        all_df.append(df)\n",
    "    if len(all_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(all_df)\n",
    "\n",
    "\n",
    "all_dfs = {}\n",
    "keys = [\"CE\", \"LS\", \"ER\", \"ERLS\", \"Focal\"]\n",
    "\n",
    "metrics = [\"ECE\", \"Brier\"]\n",
    "run_lists = [\n",
    "    all_run_ids,\n",
    "    all_run_ids_ls,\n",
    "    all_run_ids_er,\n",
    "    all_run_ids_er_ls,\n",
    "    all_run_focal,\n",
    "]\n",
    "for k, run_list in zip(keys, run_lists):\n",
    "    all_dfs[k] = defaultdict(list)\n",
    "    for m in metrics:\n",
    "        for experiment in all_experiments:\n",
    "            all_dfs[k][m].append(\n",
    "                retrieve_metrics_df(run_list[experiment[5:]], m, experiment[5:])\n",
    "            )\n",
    "        all_dfs[k][m] = pd.concat(all_dfs[k][m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"OOD\", \"ID\"]:\n",
    "    for m in [\"ECE\"]:\n",
    "        dfs_to_plot = []\n",
    "        c2 = [\n",
    "            \"probas\",\n",
    "            \"calib_ts\",\n",
    "            \"calib_irm\",\n",
    "            \"calib_irovats\",\n",
    "            \"calib_ts_with_ood\",\n",
    "            \"calib_irm_with_ood\",\n",
    "            \"calib_ebs\",\n",
    "        ]\n",
    "        cols = []\n",
    "        for p in c2:\n",
    "            cols.extend(\n",
    "                [\n",
    "                    f\"{p.replace('calib_', '').upper() }_{k}\"\n",
    "                    for k in [\"CE\", \"ERLS\", \"Focal\", \"LS\", \"ER\"]\n",
    "                ]\n",
    "            )\n",
    "        for k in [\"CE\", \"ERLS\", \"Focal\", \"LS\", \"ER\"]:\n",
    "            df1 = all_dfs[k][m][[\"domain\"] + c2]\n",
    "            clean_name = {c: c.replace(\"calib_\", \"\").upper() + f\"_{k}\" for c in c2}\n",
    "            df1.rename(columns=clean_name, inplace=True)\n",
    "            dfs_to_plot.append(df1)\n",
    "        df = pd.concat(dfs_to_plot, axis=1)\n",
    "        df = df.T.drop_duplicates().T\n",
    "        df = df.loc[df.domain == d]\n",
    "\n",
    "        # Conduct the Nemenyi post-hoc test\n",
    "        df = sp.posthoc_nemenyi_friedman(df.drop(columns=\"domain\"))\n",
    "        df = df.loc[cols]\n",
    "        df = df.T.loc[cols].T\n",
    "\n",
    "        print(pingouin.friedman(df))\n",
    "\n",
    "        f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        sns.heatmap(\n",
    "            (df < 0.05),\n",
    "            cbar=False,\n",
    "            ax=ax,\n",
    "            linecolor=\"grey\",\n",
    "            linewidth=0.00,\n",
    "            cmap=[\"white\", \"navy\"],\n",
    "        )\n",
    "        w = df.values.shape[1]\n",
    "\n",
    "        for i in range(len(c2)):\n",
    "            ax.axvline(x=i * 5, color=\"black\", linewidth=1.2)\n",
    "            ax.axhline(y=i * 5, color=\"black\", linewidth=1.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
